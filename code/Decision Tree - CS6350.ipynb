{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of decision tree for Machine Learning-CS6350\n",
    "Author: Archit Rathore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRecord:\n",
    "    '''Class to store individual data points read from train and test files'''\n",
    "\n",
    "    def __init__(self, label, name):\n",
    "        self.label = 1 if label == '+' else 0\n",
    "        self.name = ' '.join(name).lower()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.label) + ' ' + self.name\n",
    "    \n",
    "class DecisionNode:\n",
    "    '''Represent a node in the decision tree'''\n",
    "    def __init__(self, attr_index):\n",
    "        self.attr_index = attr_index    # index of attribute that is test in the \n",
    "                                        # feature array, -1 for leaf nodes\n",
    "        self.prediction = None          # the prediction from this node, None for all non-leaf nodes\n",
    "        self.branches = {}              # dictionary holding subtrees of the tree, empty for leaf nodes\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.prediction is not None:\n",
    "            return '[{0: ^4} -> \"{1}\"]'.format(self.attr_index, self.prediction)\n",
    "        else:\n",
    "            return '[{0: ^4}]'.format(str(self.attr_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filepath):\n",
    "    '''Read train or test file and return a list DataRecord objects'''\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip().split()\n",
    "            label, name = line[0], line[1:]\n",
    "            data.append(DataRecord(label, name))\n",
    "    return data\n",
    "\n",
    "def build_features(dataset, func_list):\n",
    "    '''Apply a sequence of functions to the dataset to get a feature array\n",
    "    for each data point'''\n",
    "    n, d = len(dataset), len(func_list)\n",
    "    X = np.empty((n, d), dtype=int)\n",
    "    for idx, datapoint in enumerate(dataset):\n",
    "        X[idx] = np.array([f(datapoint.name) for f in func_list])\n",
    "    return X\n",
    "\n",
    "def check_same_label(arr):\n",
    "    '''Check if all elements in arr are identical and return it'''\n",
    "    return len(set(arr)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_split(dataset, attributes, labels):\n",
    "    # Return the first attribute for now\n",
    "    return list(attributes)[0]\n",
    "\n",
    "def ID3(S, attributes, labels):\n",
    "    '''ID3 algorithm for building a decision tree'''\n",
    "    \n",
    "    # If all examples have the same label\n",
    "    if check_same_label(labels) or len(attributes) != 0:\n",
    "        # Return a single node tree with the label\n",
    "        leaf_node = DecisionNode(-1)\n",
    "        leaf_node.prediction = labels[0]\n",
    "        return leaf_node\n",
    "    \n",
    "    else:\n",
    "        # Create a root node for tree\n",
    "        root_node = DecisionNode(-1)\n",
    "        \n",
    "        print(\"Attributes\", attributes)\n",
    "        # Find attribute A that best classifies the dataset S\n",
    "        splitting_attr = find_best_split(S, attributes, labels)\n",
    "        root_node.attr_index = splitting_attr\n",
    "        \n",
    "        # For each value v that the A can take:\n",
    "        for split_val in set(S[:, splitting_attr]):\n",
    "            # Find subset of examples S_v with A = v\n",
    "            \n",
    "            # Get indices with splitting_att = split_val\n",
    "            indices = S[:, splitting_attr] == split_val    \n",
    "            # indices is a boolean indicator array \n",
    "            \n",
    "            # If S_v is empty\n",
    "            if sum(indices) == 0:\n",
    "                # Find the most common label in S\n",
    "                most_common_label = Counter(labels).most_common(1)\n",
    "                # Create a leaf node with this label\n",
    "                leaf_node = DecisionNode(-1)\n",
    "                leaf_node.prediction = most_common_label\n",
    "                # Add the leaf node to this branch of node\n",
    "                root_node.branches[split_val] = leaf_node\n",
    "                \n",
    "            else:\n",
    "                # Add subtree ID3(S_v, Attributes - {A}, Label_v)\n",
    "                S_v = S[indices]\n",
    "                label_v = labels[indices]\n",
    "                remaining_attr = attributes - {splitting_attr}\n",
    "                root_node.branches[split_val] = ID3(S_v, remaining_attr, label_v)\n",
    "                \n",
    "        return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1], [0, 0]])\n",
    "y_and = np.array([0, 1, 1, 0, 1])\n",
    "# a = ID3(X, {0, 1, 2}, y)\n",
    "a = ID3(X_and, {0,1}, y_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ID3(X, {0, 1, 2}, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = read_dataset('../Dataset/updated_train.txt')\n",
    "\n",
    "func_list = [lambda x: x[0] in ['a','e','i','o','u'],    # first letter is vowel\n",
    "             lambda x: x[-1] in ['a','e','i','o','u'],   # last letter is vowel\n",
    "             lambda x: len(x)%2 == 0                     # length of name is even\n",
    "            ]\n",
    "\n",
    "X = build_features(dataset, func_list)\n",
    "y = np.array([d.label for d in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "X_train, y_train = X[:400], y[:400]\n",
    "X_test, y_test = X[401:], y[401:]\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "47px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
